[
  
  {
    "title": "Chapter5-深入Kafka",
    "url": "/posts/Kafka_chpater2kafka_chapter5/",
    "categories": "Kafka",
    "tags": "kafka",
    "date": "2024-07-29 20:15:12 +0800",
    





    
    "snippet": "深入Kafka控制器控制器其实就是一个 broker，只不过它除了具有一般 broker 的功能之外，还负责分区首领的选举。集群里第一个启动的 broker 通过在Zookeeper 里创建一个临时节点 /controller 让自己成为控制器。其他 broker 在启动时也会尝试创建这个节点，不过它们会收到一个“节点已存在”的异常，然后“意识”到控制器节点已存在，也就是说集群里已经有一个控...",
    "content": "深入Kafka控制器控制器其实就是一个 broker，只不过它除了具有一般 broker 的功能之外，还负责分区首领的选举。集群里第一个启动的 broker 通过在Zookeeper 里创建一个临时节点 /controller 让自己成为控制器。其他 broker 在启动时也会尝试创建这个节点，不过它们会收到一个“节点已存在”的异常，然后“意识”到控制器节点已存在，也就是说集群里已经有一个控制器了。复制Kafka 使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。那些副本被保存在 broker 上，每个 broker 可以保存成百上千个属于不同主题和分区的副本。  首领副本（leader）：每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。  跟随者副本（follower）：首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求，它们唯一的任务就是从首领那里复制消息，保持与首领一致的状态。如果首领发生崩溃，其中的一个跟随者会被提升为新首领。  首选首领：创建主题时选定的首领就是分区的首选首领。之所以把它叫作首选首领，是因为在创建分区时，需要在 broker 之间均衡首。broker请求broker 的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求。broker通过TCP协议来传输请求。broker 会在它所监听的每一个端口上运行一个 Acceptor 线程，这个线程会创建一个连接，并把它交给 Processor 线程去处理。Processor 线程（也被叫作“网络线程”）的数量是可配置的。网络线程负责从客户端获取请求消息，把它们放进请求队列，然后从响应队列获取响应消息，把它们发送给客户端。所有的请求由首领副本处理。如果 broker 收到一个针对特定分区的请求，而该分区的首领在另一个 broker 上，那么发送请求的客户端会收到一个“非分区首领”的错误响应。当针对特定分区的获取请求被发送到一个不含有该分区首领的 broker上，也会出现同样的错误。Kafka 客户端要自己负责把生产请求和获取请求发送到正确的broker 上。请求格式  Request type  Request version  Correlation ID：个具有唯一性的数字，用于标识请求消息，同时也会出现在响应消息和错误日志里（用于诊断问题）  Client ID请求类型  生产请求：生产者发送的请求  获取请求：消费者或者follower副本发送的请求  元数据请求：获取首领broker信息元数据请求为获取正确的首领broker，客户端需要发送元数据请求来获取分区的首领broker。这种请求包含了客户端感兴趣的主题列表。服务器端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本，以及哪个副本是首领。元数据请求可以发送给任意一个 broker，因为所有 broker 都缓存了这些信息。物理存储Kafka 的基本存储单元是分区。分区无法在多个 broker 间进行再细分，也无法在同一个broker 的多个磁盘上进行再细分。"
  },
  
  {
    "title": "Chapter4-消费者",
    "url": "/posts/Kafka_chpater2kafka_chapter4/",
    "categories": "Kafka",
    "tags": "kafka",
    "date": "2024-07-29 20:15:12 +0800",
    





    
    "snippet": "应用程序使用 KafkaConsumer 向 Kafka 订阅主题，并从订阅的主题上接收消息。Kafka消费者通过横向伸缩提升消费者的消费能力Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。往群组里增加消费者是横向伸缩消费能力的主要方式。Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS，或者使用数据进行...",
    "content": "应用程序使用 KafkaConsumer 向 Kafka 订阅主题，并从订阅的主题上接收消息。Kafka消费者通过横向伸缩提升消费者的消费能力Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。往群组里增加消费者是横向伸缩消费能力的主要方式。Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS，或者使用数据进行比较耗时的计算。在这些情况下，单个消费者无法跟上数据生成的速度，所以可以增加更多的消费者，让它们分担负载，每个消费者只处理部分分区的消息，这就是横向伸缩的主要手段。我们有必要为主题创建大量的分区，在负载增长时可以加入更多的消费者。不过要注意，不要让消费者的数量超过主题分区的数量，多余的消费者只会被闲置。第 2 章介绍了如何为主题选择合适的分区数量。消费者群组和分区再均衡  一个新的消费者加入群组时，它读取的是原本由其他消费者读取的消息  当一个消费者被关闭或发生崩溃时，它就离开群组，原本由它读取的分区将由群组里的其他消费者来读取  主题发生变化时，比如管理员添加了新的分区，会发生分区重分配  再均衡：分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。在再均衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用。另外，当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。创建Kafka消费者消费者属性      必选属性                  bootstrap.servers：指定broker的address，格式为host：post                    key.deserializer：一个类用于反序列化key                    value.deserializer：一个类用于反序列化value                    groun.id:用于指定KafkaConsumer属于那个消费者群组                  其他属性          ` fetch.min.bytes`:该属性指定了消费者从服务器获取记录的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者.      fetch.max.wait.ms: feth.max.wait.ms 则 用 于 指 定 broker 的 等 待 时 间， 默 认 是 500ms。      max.partition.fetch.bytes:该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值是 1MB。      session.timeout.ms:该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。如果消费者没有在 session.timeout.ms 指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，把它的分区分配给群组里的其他消费者。      heartbeat.interval.ms :heartbeat.interval.ms 指 定 了 poll() 方 法 向 协 调 器发送心跳的频率，session.timeout.ms 则指定了消费者可以多久不发送心跳。所以，一般需要同时修改这两个属性，heartbeat.interval.ms 必须比 session.timeout.ms 小，一般 是 session.timeout.ms 的 三 分 之 一。 如 果 session.timeout.ms 是 3s， 那 么 heartbeat.interval.ms 应该是 1s。      auto.offset.reset:该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理。它的默认值是 latest，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 earliest，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。      enable.auto.commit:该属性指定了消费者是否自动提交偏移量，默认值是 true。      partition.assignment.strategy:根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者。有两个分配策略：Range和RoundRobin。      client.id:broker 用它来标识从客户端发送过来的消息。      max.poll.records:该属性用于控制单次调用 call() 方法能够返回的记录数量，可以帮你控制在轮询里需要处理的数据量。      receive.buffer.bytes 和 send.buffer.bytes:socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。      读取消息消费者使用poll方法读取消息。每次调用 poll() 方法，它总是返回由生产者写入 Kafka 但还没有被消费者读取过的记录，我们因此可以追踪到哪些记录是被群组里的哪个消费者读取的。  提交：我们把更新分区当前位置的操作叫作提交。  提交的几种方式          自动提交：如果 enable.auto.commit 被设为 true，那么每过 5s，消费者会自动把从 poll() 方法接收到的最大偏移量提交上去。      同步提交：使用 commitSync()提交偏移量最简单也最可靠。      异步提交：使用 commitASync()提交偏移量      同步和异步组合提交      提交特定的偏移量：以上几种方法都是提交poll方法放回数据的最后一个偏移量。      再均衡监听器消费者在退出和进行分区再均衡之前，会做一些清理工作。你会在消费者失去对一个分区的所有权之前提交最后一个已处理记录的偏移量。如果消费者准备了一个缓冲区用于处理偶发的事件，那么在失去分区所有权之前，需要处理在缓冲区累积下来的记录。你可能还需要关闭文件句柄、数据库连接等。在 为 消 费 者 分 配 新 分 区 或 移 除 旧 分 区 时， 可 以 通 过 消 费 者 API 执 行 一 些 应 用 程 序 代码， 在 调 用 subscribe() 方 法 时 传 进 去 一 个 ConsumerRebalanceListener 实 例 就 可 以 了。ConsumerRebalanceListener需要实现两个方法：  ` public void onPartitionsRevoked(Collection partitions) `方法会在再均衡开始之前和消费者停止读取消息之后被调用。如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取了。  public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) 方法会在重新分配分区之后和消费者开始读取消息之前被调用。退出读取消息要记住，consumer.wakeup() 是消费者唯一一个可以从其他线程里安全调用的方法。调用 consumer.wakeup() 可以退出 poll()，并抛出 WakeupException 异常，或者如果调用consumer.wakeup() 时线程没有等待轮询，那么异常将在下一轮调用 poll() 时抛出。"
  },
  
  {
    "title": "Chapter3-生产者",
    "url": "/posts/Kafka_chpater2kafka_chapter3/",
    "categories": "Kafka",
    "tags": "kafka",
    "date": "2024-07-29 20:15:12 +0800",
    





    
    "snippet": "kafka第三方客户端第三方客户端通过直接向Kafka网络端口发送适当的字节序列以实现从Kafka读取消息或者写入消息。构建kafka生产者      确定包含的目标topic和发送内容        指定键或分区（可选）        指定key和value的序列化器        发送消息      生产者的属性  必选属性          bootstrap.servers：指定br...",
    "content": "kafka第三方客户端第三方客户端通过直接向Kafka网络端口发送适当的字节序列以实现从Kafka读取消息或者写入消息。构建kafka生产者      确定包含的目标topic和发送内容        指定键或分区（可选）        指定key和value的序列化器        发送消息      生产者的属性  必选属性          bootstrap.servers：指定broker的address，格式为host：post      key.serializer:一个类用于序列化key      value.serializer:一个类用于序列化value            其他属性                  acks: 指定必须有多少个副本收到消息才会认为消息写入成功。                  acks=0表示不等待来自服务器的响应，能够支持最大速度发送消息，吞吐亮高。          acks=1表示收到首领节点的消息便认为消息写入成功。          acks=all表示收到参与复制的全部节点的消息时才认为消息发送成功，这个模式最安全但延迟高。                            buffer.memory:该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。                    ` compression.type`:默认情况下，消息发送时不会被压缩。该参数可以设置为 snappy、gzip 或 lz4，它指定了        消息被发送给 broker 之前使用哪一种压缩算法进行压缩。                    retries: 生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。在这种情况下，retries 参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。                    ` batch.size`: 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算（而不是消息个数）。当批次被填满，批次里的所有消息会被发送出去。不过生产者并不一定都会等到批次被填满才发送，半满        的批次，甚至只包含一个消息的批次也有可能被发送。                    linger.ms: 该参数指定了生产者在发送批次之前等待更多消息加入批次的时间。KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息。                    client.id:字符串类型，用于标识client                    max.in.flight.requests.per.connection:该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量。                    ` timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms`:request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间，metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待响应超时，那么生产者要么重试发送数据，要么返回一个错误（抛出异常或执行回调）。timeout.ms 指定了 broker 等待同步副本返回消息确认的时间，与        asks 的配置相匹配——如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误。                    client.id:该参数指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。                    max.request.size:该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指        单个请求里所有消息总的大小。                    receive.buffer.bytes 和 send.buffer.bytes:这两个参数分别指定了 TCP socket 接收和发送数据包的缓冲区大小。如果它们被设为-1，        就使用操作系统的默认值。            生产者发送消息的方式  发送并忘记（fire-and-forget）：不关心消息是否能够正常到达broker  同步发送：调用get()方法进行等待方法返回  异步发送：指定回调函数在响应返回时调用消息序列化  使用已有的序列化器和反序列化器（JSON，Avro，Thrift，Protobuf）  使用Avro进行序列化          我们把所有写入数据需要用到的 schema 保存在注册表里，然后在记录里引用 schema 的标识符。负责读取数据的应用程序使用标识符从注册表里拉取 schema 来反序列化记录。序列化器和反序列化器分别负责处理 schema 的注册和拉取。      消息格式一条Kafka消息应该包含以下内容：  目标主题  键（可以为空）：可以用来作为消息的附加信息，也可以用来决定消息被写到主题的那个分区。拥有相同键的消息将被写到同一个分区。如果键值为 null，并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。分区器使用轮询（Round Robin）算法将消息均衡地分布到各个分区上。[注意：只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变。]  值"
  },
  
  {
    "title": "Kafka安装",
    "url": "/posts/Kafka_chpater2/",
    "categories": "Kafka",
    "tags": "kafka",
    "date": "2024-07-26 14:53:12 +0800",
    





    
    "snippet": "安装kafka安装依赖      安装java依赖    wget https://builds.openlogic.com/downloadJDK/openlogic-openjdk/8u412-b08/openlogic-openjdk-8u412-b08-linux-x64.tar.gz # 安装jdk8            安装zookeeper依赖    wget https:/...",
    "content": "安装kafka安装依赖      安装java依赖    wget https://builds.openlogic.com/downloadJDK/openlogic-openjdk/8u412-b08/openlogic-openjdk-8u412-b08-linux-x64.tar.gz # 安装jdk8            安装zookeeper依赖    wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz      安装kafka  wget https://dlcdn.apache.org/kafka/3.7.1/kafka_2.13-3.7.1.tgz影响kafka性能的因素  磁盘吞吐量-影响生产者（建议选择固态硬盘）  磁盘容量  内存-影响消费者  网络延迟  CPU"
  },
  
  {
    "title": "Kafka基本概念",
    "url": "/posts/Kafka_chpater1/",
    "categories": "Kafka",
    "tags": "kafka",
    "date": "2024-07-26 10:55:12 +0800",
    





    
    "snippet": "基本概念消息和批次  kafka的消息由字节组成，消息里面的数据没有特别的格式或者含义。  效益可以有一个可选的元数据——key（键），用于为消息选择分区。  kafka消息是分批次写入的kafka，这些消息属于用一个主题或者分区。主题和分区  kafka消息通过主题进行分类，一个主题可以分为多个分区，同一个主题的不同分区可以分布在不同的服务器上。消息以FIFO的方式写入分区，以FIFO的方...",
    "content": "基本概念消息和批次  kafka的消息由字节组成，消息里面的数据没有特别的格式或者含义。  效益可以有一个可选的元数据——key（键），用于为消息选择分区。  kafka消息是分批次写入的kafka，这些消息属于用一个主题或者分区。主题和分区  kafka消息通过主题进行分类，一个主题可以分为多个分区，同一个主题的不同分区可以分布在不同的服务器上。消息以FIFO的方式写入分区，以FIFO的方式读取。生产者和消费者      生产者：发布一个消息到特定的主题上，但不关心特定消息会被写到那个分区上。        消费者：消费者订阅一个或多个主题，并按照消息生成的顺序读取他们。并通过一种元数据——偏移量来区分已经读取过的消息。        消费者群组：共同读取同一个主题的消费者构成一个消费者群组。群组保证每个分区只能被一个消费者使用。如下图所示：      broker和集群      broker：一个独立的Kafka服务器被称为broker。broke接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。        集群控制器：broker是集群的组成部分，每个集群都会选举出一个活跃的broker充当集群控制器的角色，该控制器负责管理工作。        首领：一个分区从属于一个broker，一个分区可以分配给多个broker。            保留消息策略：kafka会将消息保留一段时间或者一定大小的字节数，当超过这个限制时，旧消息会过期并被删除。每个主题可以设置单独的保留策略。  kafaka的优点  支持多个生产者、消费者  基于磁盘的数据存储，允许消费者非实时地读取消息  伸缩性，可以在线拓展集群  高性能，提供亚秒级的消息延迟kafka应用场景  活动跟踪——跟踪网站的用户活动，为机器学习系统提供数据  传递消息  度量指标和日志记录  提交日志  流处理"
  }
  
]

